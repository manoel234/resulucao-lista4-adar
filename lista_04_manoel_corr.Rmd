---
title: "Lista de Exercícios 4 - ADAR/UFSM"
author: "Manoel Antonio de Lima Neto"
date: "2023-11-03"
output: html_document
---

## Pré-requisitos

**Pacotes necessários**

```{r}
library(tidyverse)
library(openair)
library(lubridate)
library(scales)
library(rio)
library(knitr)
```

**Dados**

```{r}
lista4_data <- "dados-lista-exerc4-cap9.RData"

# download.file(
#   "https://github.com/lhmet/adar-ufsm/blob/master/data/dados-lista-exerc4-cap9.RData?raw=true",
#   destfile = lista4_data,
#   mode = "wb"
# )

# para imprimir os dados carregados
print(load(lista4_data))
```

## Exercícios

1.  Converta os dados de anomalias padronizadas do índice de oscilação sul armazenados no *quadro de dados* `soi` (mostrado abaixo) para o formato "arrumado" e em ordem cronológica. Os nomes das variáveis na tabela de dados arrumado deve estar sempre em letras minúsculas (conheça a função `tolower()`).

A estrutura esperada dos dados processados é mostrada abaixo:

```         
Rows: 36
Columns: 3
$ year <int> 1951, 1951, 1951, 1951, 1951, 1951, 19...
$ mes  <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,...
$ soi  <dbl> 1.5, 0.9, -0.1, -0.3, -0.7, 0.2, -1.0,...
```

```{r}
exerc_1 <- soi %>%
  pivot_longer(
    data = .,
    cols = -YEAR,
    names_to = "mes",
    values_to = "soi",
    values_transform = list(mes = as.numeric)
  ) %>%
  rename_with(
    .data = .,
    .fn = tolower
  ) %>%
  mutate(
    .data = .,
    # redundante, pq não fez isso no argumento `values_transform`?
    across(mes, as.integer)
  )

glimpse(exerc_1)
```


```{r jdt-correcao1, echo = FALSE, comment="JDT>"}
# penalizacoes
p1 <- 0.05
# nota questão 1
(nq1 <- 1 - p1)
```



------------------------------------------------------------------------

2.  Faça a conversão dos dados de precipitação diária, armazenados em um \*\*`tibble**`, para o "formato arrumado" e transforme as datas para o tipo de dados *date*.

```{r, eval = FALSE}
precd_ncdf
```

A estrutura esperada do **`tibble`** resultante é mostrada abaixo:

```         
Rows: 40
Columns: 4
$ x    <dbl> -60.625, -60.625, -60.625, -60.625, -60.625, -60.625, -6...
$ y    <dbl> 5.125, 5.125, 5.125, 5.125, 5.125, 5.125, 5.125, 5.125, ...
$ date <date> 2010-01-01, 2010-01-02, 2010-01-03, 2010-01-04, 2010-01...
$ prec <dbl> 0.0000000, 0.0000000, 0.0000000, 0.4484863, 2.3515625, 4...
```

```{r}
exerc_2 <- precd_ncdf %>%
  pivot_longer(
    data = .,
    cols = -c(x, y),
    names_to = "date",
    values_to = "prec"
  ) %>%
  mutate(
    .data = .,
    date = as.Date(date, "X%Y.%m.%d")
  )

glimpse(exerc_2)
```

```{r jdt-correcao2, echo = FALSE, comment = "JDT>"}
p2 <- 0.0 
(nq2 <- 1 - p2)
```


------------------------------------------------------------------------

3.  Coloque os dados de poluição (**`tibble`** `poluentes`) no formato "arrumado".

```{r}
poluentes_arrumados <- gather(poluentes, key = "variavel", value = "valor", -poluente)
colnames(poluentes_arrumados)[2] <- "observações"
print(poluentes_arrumados)


```

> Você não compreendeu a definição de 'formato arrumado':
> Verifique: há uma variável por coluna? há uma observação de cada variável 
por linha? 
> Essa seria estrutura dos dados arrumados:

```
Rows: 3
Columns: 4
$ estacao <int> 1, 2, 4
$ ozone   <chr> "1h", "8h", NA
$ so2     <chr> "1h", NA, NA
$ no2     <chr> NA, NA, "1h"
```

> Por que nas questões anteriores você usou pivot_longer e nessa ao invés de usar pivot_wider() usou gather()?
Não é errado, mas em geral ou se usa gather() e spread() ou se usa pivot_longer() e pivot_wider(). Acho as últimas mais legíveis.




```{r jdt-correcao3, echo = FALSE, comment = "JDT>"}
p3 <- 1
(nq3 <- 1 - p3)
```


------------------------------------------------------------------------

4.  

    a.  Coloque os dados meteorológicos diários da estação meteorológica de Santa Maria no formato arrumado.

```         
#> # A tibble: 12 x 35
#>    id    element month  year    d1    d2    d3    d4    d5    d6    d7    d8    d9   d10
#>    <chr> <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
#>  1 83936 tmax        1  2010  32.6  33.4  24.8  29.4  27    24.4  29.6  29.4  29.6  31.8
#>  2 83936 tmin        1  2010  17.9  21.4  21.6  23.4  23.2  21.8  18    19.4  21.8  22.4
#>  3 83936 tmax        2  2010  36.8  38.4  32.6  38.6  34    36.4  29.8  31    32.8  33.6
#>  4 83936 tmin        2  2010  25.4  25    29.6  26.2  25    25.8  25.4  22.2  19.8  17.6
#>  5 83936 tmax        3  2010  32    32.4  33.6  32.4  32    29.6  30.2  30    31    32.6
#>  6 83936 tmin        3  2010  18.6  19    20.2  21.6  19.8  18.4  17.3  21.6  20.4  22.2
#>  7 83936 tmax        4  2010  34.4  28.6  21    24.2  23.4  24    24.6  26    27.6  30.2
#>  8 83936 tmin        4  2010  17.5  21    20.6  17.6  15    10.8  11.7  11.3  12.7  11.6
#>  9 83936 tmax        5  2010  27    26.4  20.2  22.8  25.4  17.4  19.6  19.8  17.2  17.4
#> 10 83936 tmin        5  2010   7.2   7    13    16.2  14.1  11.5  14.4  11     9.9   9  
#> 11 83936 tmax        6  2010  19.2  23.8  17.2  18.6  21.2  20.2  17.8  15.4  16.2  19  
#> 12 83936 tmin        6  2010   4.1   8.8   9.1  15.2  11.4   6.1   6.3   7.3   5.6   3.5
#> # … with 21 more variables: d11 <dbl>, d12 <dbl>, d13 <dbl>, d14 <dbl>, d15 <dbl>,
#> #   d16 <dbl>, d17 <dbl>, d18 <dbl>, d19 <dbl>, d20 <dbl>, d21 <dbl>, d22 <dbl>,
#> #   d23 <dbl>, d24 <dbl>, d25 <dbl>, d26 <dbl>, d27 <dbl>, d28 <dbl>, d29 <dbl>,
#> #   d30 <dbl>, d31 <dbl>
```

```{r}
exerc_4a <- dados_sm %>%
  pivot_longer(
    data = .,
    cols = d1:d31,
    names_to = "dia",
    values_to = "valor"
  ) %>%
  pivot_wider(
    data = .,
    names_from = element,
    values_from = valor
  ) %>%
  mutate(
    .data = .,
    year = as.character(year),
    dia = as.character(dia),
    tmin = as.numeric(tmin),
    tmax = as.numeric(tmax)
  ) %>%
  unite(
    data = .,
    col = "date",
    c(dia, month, year),
    sep = "-",
  ) %>%
  mutate(
    .data = .,
    date = as.Date(x = date, format = "d%d-%m-%Y")
  )

exerc_4a

glimpse(exerc_4a)
```

> Não foi solicitado a inclusão de uma coluna com data e a remoção das demais.




b.  Deixe os dados ordenados cronologicamente e obtenha as variáveis com nomes e ordem conforme mostrado na estrutura de dados esperada.

```         
Rows: 186
Columns: 6
$ id    <chr> "83936", "83936", "83936", "83936", "83936", "...
$ year  <dbl> 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010...
$ month <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...
$ day   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,...
$ tmax  <dbl> 32.6, 33.4, 24.8, 29.4, 27.0, 24.4, 29.6, 29.4...
$ tmin  <dbl> 17.9, 21.4, 21.6, 23.4, 23.2, 21.8, 18.0, 19.4...
```

```{r}
exerc_4b <- dados_sm %>%
  pivot_longer(
    data = .,
    cols = d1:d31,
    names_to = "day",
    values_to = "valor"
  ) %>%
  pivot_wider(
    data = .,
    names_from = element,
    values_from = valor
  ) %>%
  mutate(
    .data = .,
    day = parse_number(day)
  ) %>%
  relocate(
    .data = .,
    year,
    .before = month
  ) |> 
  # FALTOU ARRANGE() para garantir que os dados ficariam ordenados
  arrange(year, month, day) 

glimpse(exerc_4b)
```

> Para que repetir código, um dos mantras da programação é "nunca se repita". Poderia ter usado o resultado da (a).


c.  Acrescente uma nova variável `tmed` aos dados de temperatura diária arrumados, obtida da média diária da `tmax` e `tmin`.

```{r}
exerc_4c <- exerc_4b %>%
  mutate(
    .data = .,
    tmed = (tmax + tmin) / 2
  )

exerc_4c
```



```{r jdt-correcao4, echo = FALSE, comment = "JDT>"}
p4 <- 0.2 # (repetição de código) e falta do arrange()
(nq4 <- 1 - p4)
```


------------------------------------------------------------------------

5.  Com os dados obtidos na questão 4c:

    a.  renomeie as as colunas `year`, `month` e `day`para `ano`, `mes` e `dia`, respectivamente.

```{r}
exerc_5a <- exerc_4c %>%
  rename(
    .data = .,
    ano = year,
    mes = month,
    dia = day
  )

exerc_5a
```

b.  junte as colunas `ano`, `mes` e `dia` em uma única coluna denominada `data` de forma que a classe dessa nova váriavel seja `date`.

```{r}
exerc_5b <- exerc_5a %>%
  mutate(
    across(c(ano, mes, dia), as.character)
  ) %>%
  unite(
    data,
    dia, mes, ano,
    sep = "-"
  ) %>%
  mutate(
    data = as.Date(data, format = "%d-%m-%Y")
  )

exerc_5b
```

c.  Filtre os dados obtidos em **(b)** de forma a descobrir as datas em que as observações de `tmax` ou `tmin` são faltantes. Mostre o **`tibble`** filtrado com as datas e explique o porquê de seus valores. *DICA: quantas observações são esperadas por ano?*.

```{r}
filter(exerc_5b, is.na(tmin) | is.na(tmax))
slice(exerc_5b, which(is.na(tmin)) + 1)
slice(exerc_5b, which(is.na(tmin)) - 1)

exerc_5c <- exerc_5b %>%
  filter(
    .data = .,
    !is.na(tmin),
    !is.na(tmax)
  )

exerc_5c

glimpse(exerc_5c)
```


```{r jdt-correcao5, echo = FALSE, comment = "JDT>"}
p5 <- 0
(nq5 <- 1 - p5)
```


------------------------------------------------------------------------

6.  A amostra de dados abaixo possui medidas a cada 6 horas de uma estação meteorológica de superfície. Reestruture os dados no formato "arrumado" e junte as informações de data e horário em uma única variável da classe *POSIXct* denominada `date`.

```         
#>         date tmax.0 tmax.600 tmax.1200 tmax.1800 tmin.0 tmin.600 tmin.1200 tmin.1800
#> 2 01-01-2010   22.1     21.0      26.4      27.0     16     13.5      18.2      24.1
#> 3 02-01-2010   26.0     25.0      29.4      29.5     19     13.7      16.3      22.3
#> 4 03-01-2010   25.7     26.3      28.4      29.0     21     14.1      17.2      26.0
#> 5 04-01-2010   23.5     24.5      27.4      28.0     23     16.2      16.9      23.0
```

A estrutura esperada do *tibble* resultante é mostrada abaixo:

```         
Rows: 16
Columns: 3
$ date <dttm> 2010-01-01 00:00:00, 2010-01-01 06:00:00, 2010-01-01 12:00:00, 2010-01-01 18:...
$ tmax <dbl> 22.1, 21.0, 26.4, 27.0, 26.0, 25.0, 29.4, 29.5, 25.7, 26.3, 28.4, 29.0, 23.5, ...
$ tmin <dbl> 16.0, 13.5, 18.2, 24.1, 19.0, 13.7, 16.3, 22.3, 21.0, 14.1, 17.2, 26.0, 23.0, ...
```

```{r}
exerc_6 <- dados_zorra %>%
  pivot_longer(
    data = .,
    cols = -date,
    names_to = "variavel",
    values_to = "valor"
  ) %>%
  separate(
    data = .,
    col = variavel,
    into = c("variavel", "hora"),
    sep = "[.]"
  ) %>%
  mutate(
    .data = .,
    hora = sprintf("%02d", (as.integer(hora)) / 100)
  ) %>%
  unite(
    data = .,
    col = date,
    date, hora,
    sep = "-"
  ) %>%
  pivot_wider(
    data = .,
    names_from = variavel,
    values_from = valor
  ) %>%
  mutate(
    .data = .,
    # NO LIVRO DO CURSO FOI ENSINADO as.POSIXct()
    # AO IMPRIMIR O OBJETO VOCÊ VERÁ QUE SAI NO FORMATO LISTA A SAIDA DA strptime()
    # ao usar algumas funções não funcionará
    # openair::timePlot(exerc_6, c("tmax"))
    #  Error in checkPrep(mydata, vars, type, remove.calm = FALSE) : 
    #  date should be in POSIXct format not POSIXlt
    date = strptime(x = date, format = "%d-%m-%Y-%H")
  )
exerc_6
glimpse(exerc_6)
```

```{r jdt-correcao6, echo = FALSE, comment = "JDT>"}
p6 <- 0.2 # 
(nq6 <- 1 - p6)
```

------------------------------------------------------------------------

7.  Faça uma junção da tabela de dados de informações das estações de poluição (`estacoes`, dada abaixo) com os períodos de duração de poluição crítica (`poluentes`). A tabela resultante deve conter somente estações que tenham coordenadas espaciais e medidas de poluentes válidas.

Estrutura da tabela resultante:

```         
Rows: 3
Columns: 5
$ id       <int> 1, 1, 2
$ lat      <dbl> 42.46757, 42.46757, 42.04915
$ lon      <dbl> -87.81005, -87.81005, -88.27303
$ poluente <chr> "ozone", "so2", "ozone"
$ duracao  <chr> "1h", "1h", "8h"
```

```{r}
exerc_7 <- inner_join(
  x = estacoes,
  y = poluentes,
  by = c("id" = "estacao")
)

glimpse(exerc_7)
```


```{r jdt-correcao7, echo = FALSE, comment = "JDT>"}
p7 <- 0
(nq7 <- 1 - p7)
```

------------------------------------------------------------------------

8.  Combine as 2 tabelas abaixo de forma que:

```{=html}
<!-- -->
```
a.  A tabela resultante contenha todas as datas compreendidas pelas duas tabelas (e em ordem cronológica) e as observações de umidade do solo (`theta`) sejam preenchidas com `NA`.

```{r}
exerc_8a <- full_join(
  x = datas_comp,
  y = datas_obs
) %>%
  arrange(
    .data = .,
    date
  )
exerc_8a
glimpse(exerc_8a)
```

b.  a tabela resultante contenha exatamente as datas da tabela `data_comp` (em ordem cronológica) e as observações de umidade do solo (`theta`) sejam preenchidas com `NA`.

```{r}
exerc_8b <- left_join(
  x = datas_comp,
  y = datas_obs
) %>%
  arrange(
    .data = .,
    date
  )

glimpse(exerc_8b)
exerc_8b
```


```{r jdt-correcao8, echo = FALSE, comment = "JDT>"}
p8 <- 0
(nq8 <- 1 - p8)
```

------------------------------------------------------------------------

9.  Utilizando os dados horários de estações meteorológicas automáticas (EMA) do RS (`dados_rs_08_16`), determine a data inicial, final e o período de dados (em anos) de cada estação (identificada pela variável `site`).

```{r}
exerc_9 <- group_by(
  .data = dados_rs_08_16,
  site
) %>%
  summarise(
    .data = .,
    inicio = first(date), #  correto e mais seguro é usar o min(date)
    fim = last(date),     #  correto e mais seguro é usar o max(date)
    period = as.numeric((fim - inicio) / 365)
  )

glimpse(exerc_9)
```
> Não é tão simples assim! Compare com os resultados abaixo.

```{r}
# diferenças no periodo para A899
por_ano <- dados_rs_08_16 %>% 
  #filter(site == "A899") %>%
  select(site, date) %>%
  group_by(site, year = year(date)) %>%
  summarise(
    inicio = min(date),
    fim = max(date),
    #periodo = as.vector((fim - inicio)/365.25)
    #fracao_dias_com_obs = n()/24, #
    #dias_calendario = ifelse(unique(year(date)) %% 4 == 0, 366, 365), 
    #periodo = fracao_dias_com_obs/dias_calendario,
    intervalo = time_length(interval(inicio, fim), "year"),
    .groups = "drop"
    ) 
por_site <- por_ano %>%
  group_by(site) %>%
 summarise(inicio = min(inicio), 
           fim = max(fim), 
           #dias_com_obs = sum(fracao_dias_com_obs), 
           #dias_calendario = sum(dias_calendario),
           #periodo = round(sum(periodo), 2),
           period_interv = round(sum(intervalo), 2),
           .groups = "drop"
           ) 
por_site
```


```{r jdt-correcao9, echo = FALSE, comment = "JDT>"}
p9 <- 0.5
(nq9 <- 1 - p9)
```

------------------------------------------------------------------------

10. Determine a porcentagem de dados válidos (ou seja, não faltantes) de cada variável para cada EMA. Aproxime os valores para números inteiros.

```{r}
exerc_10 <- dados_rs_08_16 %>%
  group_by(
    .data = .,
    site
  ) %>%
  summarise(
    .data = .,
    tair = as.integer(100 * sum(!is.na(tair)) / n()),
    rh = as.integer(100 * sum(!is.na(rh)) / n()),
    prec = as.integer(100 * sum(!is.na(prec)) / n()),
    rg = as.integer(100 * sum(!is.na(rg)) / n()),
    ws = as.integer(100 * sum(!is.na(ws)) / n())
  )

glimpse(exerc_10)
```

> evite repetir codigo, veja uma solucao usando uma funcao e across()

```{r solucao-10}
perc_valid <- function(x){
  #if(all(is.na(x))) return(0)
  #sum(!is.na(x))/length(x) * 100
  as.integer(mean(!is.na(x)) * 100)
} 

validos <- dados_rs_08_16 %>%
  group_by(site) %>%
  summarise(across(tair:ws, perc_valid)) 
glimpse(validos)
```


```{r jdt-correcao10, echo = FALSE, comment = "JDT>"}
p10 <- 0
(nq10 <- 1 - p10)
```


------------------------------------------------------------------------

11. Com o resultado da questão anterior, adicione uma variável indicativa da porcentagem média de observações válidas de todas variáveis. Ordene esta tabela em ordem decrescente da disponibilidade média de observações.

```{r}
exerc_11 <- exerc_10 %>%
  mutate(
    .data = .,
    disp_med = (tair + rh + prec + rg + ws) / 5
  ) %>%
  arrange(
    .data = .,
    desc(disp_med)
  )

glimpse(exerc_11)
```

> Ok, mas veja como pode ser aperfeiçoado seu código:

```{r}
disp <- validos %>% 
  # mutate(., disp_med = rowMeans(.[,-1])) %>% # possibilidade 1
  rowwise(site) %>%
  #mutate(disp_med = mean(c(tair, rh, prec, rg, ws))) %>% # possibilidade 2
  mutate(disp_med = mean(c_across(tair:ws))) %>% # # possibilidade 3 - best
  arrange(desc(disp_med))
disp
```


```{r jdt-correcao11, echo = FALSE, comment = "JDT>"}
p11 <- 0
(nq11 <- 1 - p11)
```


------------------------------------------------------------------------

12. Para a EMA de Santa Maria (ver `info_emas_rs_08_16`) obtenha o ciclo diurno médio da temperatura do ar e a porcentagem de dados válidos usados para compor a `tair` média de cada hora.

> Dica: Para extrair as horas das datas use a função `lubridate::hour(date)`.

```{r}
sm_str <- info_emas_rs_08_16 %>%
  filter(
    .data = .,
    name == "SANTA MARIA"
  ) %>%
  pull(site)

exerc_12 <- dados_rs_08_16 %>%
  filter(
    .data = .,
    site == sm_str
  ) %>%
  group_by(
    .data = .,
    lubridate::hour(date)
  ) %>%
  summarise(
    .data = .,
    tair_med = mean(tair, na.rm = TRUE),
    disp_med = 100 * sum(!is.na(tair)) / n()
  ) %>%
  rename(
    .data = .,
    hour = "lubridate::hour(date)"
  )

glimpse(exerc_12)
```

```{r jdt-correcao12, echo = FALSE, comment = "JDT>"}
p12 <- 0
(nq12 <- 1 - p12)
```

------------------------------------------------------------------------

13. Com os dados de temperatura do ar (`tair`) filtrados para EMA de Santa Maria (a) selecione somente os dias observações válidas nas 24 horas (dias completos, ou seja, sem nenhuma falha nas 24 h). A partir destes dados (b) obtenha a frequência de ocorrência da temperatura mínima para cada horário do dia. (c) Apresente a tabela de resultados em ordem decrescente da frequência de ocorrência.

> Dica: para obter o dia a partir da data e hora (coluna `date` do tipo `POSIXct`) use `lubridate::floor_date(date, unit = "day")`.

**SOLUÇÕES**

**a)**

```{r}
exerc_13a <- dados_rs_08_16 %>%
  filter(
    .data = .,
    site == sm_str
  ) %>%
  group_by(
    .data = .,
    dias_completos = lubridate::floor_date(date, unit = "day")
  ) %>%
  summarise(
    .data = .,
    valido = mean(tair),
    horas = n()
  ) %>%
  filter(
    .data = .,
    !is.na(valido) & horas == 24
  ) %>%
  select(
    .data = .,
    dias_completos
  )

glimpse(exerc_13a)
glimpse(tail(exerc_13a))
```

**b)**

```{r}
exerc_13b <- dados_rs_08_16 %>%
  filter(
    .data = .,
    lubridate::floor_date(date, unit = "day") %in% exerc_13a$dias_completos,
    site == sm_str
  ) %>%
  group_by(
    .data = .,
    dias_completos = lubridate::floor_date(date, unit = "day")
  ) %>%
  summarise(
    .data = .,
    min = min(tair),
    h_tmin = lubridate::hour(date)[which.min(tair)]
  ) %>%
  group_by(
    .data = .,
    h_tmin
  ) %>%
  summarise(
    .data = .,
    n = n()
  )

glimpse(exerc_13b)
```

**c)**

```{r}
exerc_13c <- exerc_13b %>%
  arrange(
    .data = .,
    desc(n)
  )

glimpse(exerc_13c)
```

```{r jdt-correcao13, echo = FALSE, comment = "JDT>"}
p13 <- 0
(nq13 <- 1 - p13)
```


------------------------------------------------------------------------

14. Neste exercício aplicaremos um controle de qualidade básico de dados meteorológicos. Você irá verificar se nos dados da EMA de Santa Maria (A803, mesmos dados do item **a** do exercício anterior) ocorreram casos em que a temperatura máxima (mínima) diária foi acima (abaixo) dos recordes históricos registrados pela estação meteorológica convencional do INMET de Santa Maria (site 83936). Os recordes históricos de temperatura máxima e mínima estão disponíveis nos dados `recordes_temp` para cada mês do ano. Você deve obter os casos suspeitos na estrutura conforme abaixo.

```         
# A tibble: 8 x 7
  date                 tmax  tmin   mes site 
  <dttm>              <dbl> <dbl> <dbl> <chr>
1 2009-10-30 00:00:00  35.8  20.4    10 83936
2 2009-10-31 00:00:00  36.8  21.8    10 83936
3 2013-12-26 00:00:00  38.3  21.2    12 83936
4 2014-02-05 00:00:00  38    23.8     2 83936
5 2014-02-06 00:00:00  38.3  24.4     2 83936
6 2014-02-07 00:00:00  39.5  23.2     2 83936
7 2014-02-09 00:00:00  38.3  22.9     2 83936
8 2014-10-29 00:00:00  36.8  22.4    10 83936
# ... with 2 more variables: tmin_abs <dbl>,
#   tmax_abs <dbl>
```

```{r}
recordes_sm <- recordes_temp %>%
  filter(
    .data = .,
    site == 83936
  )

exerc_14 <- dados_rs_08_16 %>%
  filter(
    .data = .,
    lubridate::floor_date(date, unit = "day") %in% exerc_13a$dias_completos,
    site == sm_str,
  ) %>%
  group_by(
    .data = .,
    day = lubridate::floor_date(date, unit = "day"),
  ) %>%
  summarise(
    .data = .,
    tmax = max(tair),
    tmin = min(tair)
  ) %>%
  mutate(
    .data = .,
    month = lubridate::month(day),
    site_ema = sm_str
  ) %>%
  full_join(
    x = .,
    y = recordes_sm,
    by = "month"
  ) %>%
  select(
    .data = .,
    site_ema,
    day,
    tmax,
    tmin,
    month,
    site_emc = site,
    tmax_abs,
    tmin_abs,
  ) %>%
  filter(
    .data = .,
    tmax > tmax_abs | tmin < tmin_abs
  )

exerc_14

glimpse(exerc_14)
```

```{r jdt-correcao14, echo = FALSE, comment = "JDT>"}
p14 <- 0
(nq14 <- 1 - p14)
```


```{r jdt-nota-final, comment = "JDT>", echo=FALSE}
# requer conexão de internet
source("https://gist.githubusercontent.com/lhmet/3ddfc43bcf796c81ecfd9bb93f5f5dc2/raw/b489a6bb4d948472afa5068256b7869a7997e109/aux-funs-list-correction")
coleta_notas
# verificação de autoria
nota <- round((sum(coleta_notas)/length(coleta_notas) * 10), 1)
message("Nota: ", nota)

```

